import requestsimport scrapyimport timefrom selenium import webdriverfrom selenium.webdriver.chrome.options import Optionsimport sysfrom scrapy import Request, signalsfrom tools.getFilterName import getLagouPositionUrl, getZhiLianPositionUrl, get51jobPositionUrl,get51job2017PositionUrlfrom RecruitSpider.items import Job51ItemLoader, Job51PositionItem, ZhilianItemLoader, ZhilianItem, LagouItemLoader, LagouItemfrom tools.seleniumTest import lagouLoginclass stateSpider(scrapy.Spider):    name = 'state'    allowed_domains = ['www.lagou.com', 'jobs.zhaopin.com', 'jobs.51job.com']    custom_settings = {        'HTTPERROR_ALLOWED_CODES': [404, 301],        'ITEM_PIPELINES': {            'RecruitSpider.pipelines.stateSpiderPipeline': 300,        },    }    headers = {        'Accept': 'application/json, text/javascript, */*; q=0.01',        'Accept-Language': 'zh-CN,zh;q=0.8,en;q=0.6',        'Referer': 'https://www.lagou.com/jobs/list_?px=new&city=%E5%85%A8%E5%9B%BD',        'Origin': 'https://www.lagou.com',        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.101 Safari/537.36",        'X-Anit-Forge-Code': '0',        'X-Anit-Forge-Token': 'None',        'X-Requested-With': 'XMLHttpRequest'    }    lagouPositionUrl = []           #loagou职位列表    zhilainPositionUrl = []         #zhilian职位列表    jobPositionUrl = []           #51job职位列表    job2017PositionUrl = []      #51job2017年的职位列表    lagou_url = getLagouPositionUrl()    for each_lagou in lagou_url:        lagouPositionUrl.append(each_lagou)    zhilian_url = getZhiLianPositionUrl()    for each_zhilian in zhilian_url:        zhilainPositionUrl.append(each_zhilian)    job_url = get51jobPositionUrl()    for each in job_url:        jobPositionUrl.append(each)    job2017_url = get51job2017PositionUrl()    for each in job2017_url:        job2017PositionUrl.append(each)    def __init__(self, **kwargs):        super(stateSpider,self).__init__()        # 谷歌浏览器        # 如果是linux环境 则开启无界面        if 'linux' in sys.platform:            from pyvirtualdisplay import Display            self.display = Display(visible=0,size=(1024,768))            self.display.start()        chrome_opt = Options()        prefs = {"profile.managed_default_content_sttings.images": 2}        chrome_opt.add_experimental_option("prefs", prefs)        chrome_opt.add_argument("--no-sandbox")        chrome_opt.add_argument("--disable-setuid-sandbox")        self.browser = webdriver.Chrome( chrome_options=chrome_opt)    # 爬虫信号绑定    @classmethod    def from_crawler(cls, crawler, *args, **kwargs):        spider = super(stateSpider, cls).from_crawler(crawler, *args, **kwargs)        crawler.signals.connect(spider.spider_close, signals.spider_closed)        return spider    def spider_close(self, spider):        print('spider close')        self.browser.quit()        if 'linux' in sys.platform:            self.display.stop()    def start_requests(self):        cookies = lagouLogin('dict', self.browser)        for i in range(0, len(self.lagouPositionUrl)):            yield  Request(url=self.lagouPositionUrl[i], callback=self.lagouDetail, dont_filter=True, cookies=cookies,                           meta={'url': self.lagouPositionUrl[i]}, headers=self.headers)        for i in range(0, len(self.zhilainPositionUrl)):            yield  Request(url=self.zhilainPositionUrl[i], callback=self.zhilianDetail, dont_filter=True, meta={'url': self.zhilainPositionUrl[i]})        for i in range(0, len(self.jobPositionUrl)):            yield  Request(url=self.jobPositionUrl[i], callback=self.jobDetail, dont_filter=True, meta={'url': self.jobPositionUrl[i]})        for i in range(0, len(self.job2017PositionUrl)):            yield  Request(url=self.job2017PositionUrl[i], callback=self.job2017Detail, dont_filter=True, meta={'url': self.job2017PositionUrl[i]} )    def lagouDetail(self, response):        url = response.meta.get('url')        item_loader = LagouItemLoader(item=LagouItem(), response=response)        # 处理已失效职位        states = response.xpath(            '//div[@class="position-head"]/div[@class="position-content "]/div[@class="position-content-r clearfix"]'            '/div[@class="position-deal clearfix"]/div[@class="resume-deliver"]/a/text()').extract_first()        if states == "投个简历":            state = 0            endTime = '未结束'        elif states == "已下线":            state = 1            endTime = time.strftime("%Y-%m-%d", time.localtime())        elif states is None:            state = 1            endTime = "该信息已被删除"        item_loader.add_value('state', state)        item_loader.add_value('endTime', endTime )        item_loader.add_value('url', url)        lagou_item = item_loader.load_item()        yield lagou_item    def zhilianDetail(self, response):        url = response.meta.get('url')        item_loader = ZhilianItemLoader(item=ZhilianItem(), response=response)        # 处理已经失效的职位        states = response.xpath('//div[contains(@class,"terminalpage-left")]/ul/li').extract()        if len(states) == 9:            state = 1            endTime = time.strftime("%Y-%m-%d", time.localtime())        else:            state = 0            endTime = "未结束"        item_loader.add_value('state', state)        item_loader.add_value('endTime', endTime)        item_loader.add_value('url', url)        position_detail_item = item_loader.load_item()        yield position_detail_item    def jobDetail(self, response):        url = response.meta.get('url')        item_loader = Job51ItemLoader(item=Job51PositionItem(), response=response)        # 处理已失效职位        code = requests.get(url).status_code        if code == 200:            state = 0            endTime = "未结束"        else:            state = 1            endTime = time.strftime("%Y-%m-%d", time.localtime())        item_loader.add_value('state', state)        item_loader.add_value('endTime', endTime)        item_loader.add_value('url', url)        job51_item = item_loader.load_item()        yield job51_item    def job2017Detail(self, response):        url = response.meta.get('url')        item_loader = Job51ItemLoader(item=Job51PositionItem(), response=response)        year = "2017"        # 处理已失效职位        code = requests.get(url).status_code        if code == 404:            state = 1            endTime = time.strftime("%Y-%m-%d", time.localtime())        else:            state = 0            endTime = "未结束"        item_loader.add_value('state', state)        item_loader.add_value('endTime', endTime)        item_loader.add_value('url', url)        item_loader.add_value('year', year)        job51_item = item_loader.load_item()        yield job51_item